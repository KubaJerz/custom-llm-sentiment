{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a36e8274",
   "metadata": {},
   "source": [
    "Loosely following:\n",
    " \n",
    "https://www.datacamp.com/tutorial/fine-tuning-large-language-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1324b8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, Gemma3ForCausalLM\n",
    "from huggingface_hub import login\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17c38933",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "HUGGINGFACE_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "MODEL = \"google/gemma-3-4b-it\"\n",
    "SEED = 69\n",
    "device = 'mps'\n",
    "\n",
    "login(token=HUGGINGFACE_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "242f85ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = load_dataset(\"mteb/tweet_sentiment_extraction\")\n",
    "df = pd.DataFrame(raw_dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ad3774d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                             ed167662a5\n",
       "text           But it was worth it  ****.\n",
       "label                                   2\n",
       "label_text                       positive\n",
       "Name: 26730, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[26730]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "feed4834",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd20ab6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding:  {'input_ids': [[0, 0, 0, 0, 2, 23391, 1902], [2, 236763, 13990, 1133, 531, 9039, 19406]], 'attention_mask': [[0, 0, 0, 0, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1]]}\n",
      "decoding:  ['<pad><pad><pad><pad><bos>hello world', '<bos>bobby like to eat pizza']\n"
     ]
    }
   ],
   "source": [
    "text = ['hello world', 'bobby like to eat pizza']\n",
    "vec = tokenizer(text, padding=True)\n",
    "print(\"encoding: \",vec)\n",
    "\n",
    "print(\"decoding: \",tokenizer.batch_decode(vec['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed4808b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_dataset(data):\n",
    "    return tokenizer(data['text'], padding=\"max_length\", truncation=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94fe379d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3432/3432 [00:00<00:00, 36735.80 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = raw_dataset.map(tokenize_dataset, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0052a7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset['train'].shuffle(SEED).select(range(2))\n",
    "test = dataset['test'].shuffle(SEED).select(range(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f31a9ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.72s/it]\n"
     ]
    }
   ],
   "source": [
    "#since we are using gemma we need to def a model for seq classification\n",
    "\n",
    "baseModel = Gemma3ForCausalLM.from_pretrained(MODEL, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b8b7b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseModel.config.output_hidden_states = True          \n",
    "baseModel.gradient_checkpointing_enable()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2e4264a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gemma3Classifier(nn.Module):\n",
    "    def __init__(self, bmodel, hiddensize, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.bmodel = bmodel\n",
    "        self.dropout = dropout \n",
    "        self.head = nn.Linear(hiddensize, 3)\n",
    "    \n",
    "    def forward(self, input, attention_mask):\n",
    "        out = self.bmodel(input, attention_mask)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5078d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Gemma3Classifier(bmodel=baseModel, dropout=0.1, hiddensize=baseModel.config.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9882b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(input=torch.tensor(train['input_ids']).to(device), attention_mask = torch.tensor(train['attention_mask']).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "879ed0c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128, 262208])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['logits'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a624a03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560,\n",
       "         114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560,\n",
       "         114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560,\n",
       "         114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560,\n",
       "         114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560,\n",
       "         114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560,\n",
       "         114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560,\n",
       "         114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560,\n",
       "         114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560,\n",
       "         114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560,\n",
       "         114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560,\n",
       "         114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560,\n",
       "         114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560,\n",
       "         114560, 114560,    818, 236761, 236764,    600, 236789, 236751,  12864,\n",
       "         236888,    108],\n",
       "        [114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560,\n",
       "         114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560,\n",
       "         114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560,\n",
       "         114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560,\n",
       "         114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560,\n",
       "         114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560,\n",
       "         114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560,\n",
       "         114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560,\n",
       "         114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560,\n",
       "         114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560,\n",
       "         114560, 114560, 114560, 114560, 114560, 114560, 114560, 114560,    818,\n",
       "            818,   4301,    496,   3198, 236743,  20705,  10790,   1074,    529,\n",
       "         119072, 236761,   3418,  47264,   2519,    659,   7399,    528, 236761,\n",
       "           3645,   6029, 236761,    108,   3198,    506,   2519,    659,    786,\n",
       "            735,   1679]], device='mps:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_id = torch.argmax(out['logits'], dim=-1)\n",
    "pred_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d75de29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column([' awww, that`s cute.', 'On train with at least two gaggles of teenagers sitting & the commuters squished standing in the back...at least the teenagers let me sit'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIX UNIXTheThe travel a least  passengershoules of geese. across staring train areishing in. front middle.\\n\\n least the train are me have down'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train['text'])\n",
    "res =  tokenizer.batch_decode(pred_id.cpu())[1]\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "454313a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TheThe travel a least  passengershoules of geese. across staring train areishing in. front middle.\\n\\n least the train are me have down'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.strip(\" UNIX \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
